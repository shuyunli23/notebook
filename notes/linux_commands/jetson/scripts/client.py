# vision_concurrent_client.py
import asyncio
import aiohttp
import time
import json
from typing import List, Dict, Any
import statistics
from datetime import datetime
import argparse
import base64
import requests
from io import BytesIO
from PIL import Image


class VisionConcurrentClient:
    def __init__(self, base_url: str = "http://localhost:8001"):
        self.base_url = base_url
        self.results = []

    def encode_image_to_base64(self, image_url: str) -> str:
        """å°†å›¾ç‰‡URLè½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()

            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')

            # æ£€æµ‹å›¾ç‰‡æ ¼å¼
            content_type = response.headers.get('content-type', 'image/jpeg')
            if 'png' in content_type:
                mime_type = 'image/png'
            elif 'gif' in content_type:
                mime_type = 'image/gif'
            else:
                mime_type = 'image/jpeg'

            return f"data:{mime_type};base64,{image_base64}"

        except Exception as e:
            print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥ {image_url}: {e}")
            return None

    async def send_vision_request(self, session: aiohttp.ClientSession, request_id: int,
                                  image_url: str, text_prompt: str, max_tokens: int = 512) -> Dict[str, Any]:
        """å‘é€è§†è§‰ç†è§£è¯·æ±‚"""

        # é¢„å¤„ç†å›¾ç‰‡ï¼ˆè½¬æ¢ä¸ºbase64ï¼‰
        print(f"ğŸ–¼ï¸  è¯·æ±‚ {request_id}: æ­£åœ¨åŠ è½½å›¾ç‰‡...")
        image_data = self.encode_image_to_base64(image_url)

        if not image_data:
            return {
                'request_id': request_id,
                'success': False,
                'error': 'Failed to load image',
                'total_time': 0,
                'tokens_per_second': 0,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            }

        # æ„å»ºè¯·æ±‚æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_data  # ä½¿ç”¨base64ç¼–ç çš„å›¾ç‰‡
                        }
                    },
                    {
                        "type": "text",
                        "text": text_prompt
                    }
                ]
            }
        ]

        payload = {
            # "model": "Qwen/Qwen3-VL-4B-Instruct",
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": 0.7,
            "stream": False
        }

        start_time = time.time()
        print(f"ğŸš€ è¯·æ±‚ {request_id}: å¼€å§‹å¤„ç†...")

        try:
            async with session.post(f"{self.base_url}/v1/chat/completions", json=payload) as response:
                if response.status == 200:
                    result = await response.json()
                    end_time = time.time()

                    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                    total_time = end_time - start_time

                    # è·å–ç”Ÿæˆçš„æ–‡æœ¬å’Œtokenæ•°é‡
                    generated_text = result['choices'][0]['message']['content']

                    # è·å–tokenä½¿ç”¨æƒ…å†µ
                    usage = result.get('usage', {})
                    completion_tokens = usage.get('completion_tokens', len(generated_text.split()))
                    prompt_tokens = usage.get('prompt_tokens', 0)
                    total_tokens = usage.get('total_tokens', completion_tokens + prompt_tokens)

                    # è®¡ç®—ç”Ÿæˆé€Ÿåº¦
                    tokens_per_second = completion_tokens / total_time if total_time > 0 else 0

                    return {
                        'request_id': request_id,
                        'success': True,
                        'image_url': image_url,
                        'text_prompt': text_prompt,
                        'response': generated_text,
                        'total_time': total_time,
                        'prompt_tokens': prompt_tokens,
                        'completion_tokens': completion_tokens,
                        'total_tokens': total_tokens,
                        'tokens_per_second': tokens_per_second,
                        'timestamp': datetime.now().strftime("%H:%M:%S")
                    }
                else:
                    error_text = await response.text()
                    return {
                        'request_id': request_id,
                        'success': False,
                        'error': f"HTTP {response.status}: {error_text}",
                        'total_time': time.time() - start_time,
                        'tokens_per_second': 0,
                        'timestamp': datetime.now().strftime("%H:%M:%S")
                    }

        except Exception as e:
            return {
                'request_id': request_id,
                'success': False,
                'error': str(e),
                'total_time': time.time() - start_time,
                'tokens_per_second': 0,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            }

    async def run_vision_concurrent_requests(self, test_cases: List[Dict], max_tokens: int = 512):
        """å¹¶å‘è¿è¡Œå¤šä¸ªè§†è§‰ç†è§£è¯·æ±‚"""

        print(f"ğŸš€ å¼€å§‹è§†è§‰æ¨¡å‹å¹¶å‘æµ‹è¯•...")
        print(f"ğŸ“Š è¯·æ±‚æ•°é‡: {len(test_cases)}")
        print(f"ğŸ¯ æœ€å¤§tokenæ•°: {max_tokens}")
        print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {self.base_url}")
        print("-" * 80)

        connector = aiohttp.TCPConnector(limit=10)
        timeout = aiohttp.ClientTimeout(total=600)  # 10åˆ†é’Ÿè¶…æ—¶ï¼ˆå›¾ç‰‡å¤„ç†éœ€è¦æ›´é•¿æ—¶é—´ï¼‰

        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = [
                self.send_vision_request(
                    session,
                    i,
                    case['image_url'],
                    case['text_prompt'],
                    max_tokens
                )
                for i, case in enumerate(test_cases, 1)
            ]

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            overall_start = time.time()
            results = await asyncio.gather(*tasks, return_exceptions=True)
            overall_end = time.time()

            # å¤„ç†ç»“æœ
            self.results = []
            for result in results:
                if isinstance(result, Exception):
                    self.results.append({
                        'success': False,
                        'error': str(result),
                        'tokens_per_second': 0
                    })
                else:
                    self.results.append(result)

            # æ˜¾ç¤ºç»“æœ
            self.display_vision_results(overall_end - overall_start)

    def display_vision_results(self, total_time: float):
        """æ˜¾ç¤ºè§†è§‰æµ‹è¯•ç»“æœ"""

        print("\n" + "=" * 100)
        print("ğŸ“‹ è§†è§‰ç†è§£æµ‹è¯•è¯¦ç»†ç»“æœ:")
        print("=" * 100)

        successful_requests = []
        failed_requests = []

        for result in self.results:
            if result['success']:
                successful_requests.append(result)
                print(f"âœ… è¯·æ±‚ {result['request_id']} [{result['timestamp']}]")
                print(f"   ğŸ–¼ï¸  å›¾ç‰‡: {result['image_url']}")
                print(f"   ğŸ“ æç¤º: {result['text_prompt']}")
                print(f"   â±ï¸  è€—æ—¶: {result['total_time']:.2f}s")
                print(f"   ğŸ¯ ç”ŸæˆToken: {result['completion_tokens']} ä¸ª")
                print(f"   âš¡ é€Ÿåº¦: {result['tokens_per_second']:.2f} tokens/s")
                print(f"   ğŸ’¬ å›å¤: {result['response'][:800]}{'...' if len(result['response']) > 800 else ''}")
                print("-" * 80)
            else:
                failed_requests.append(result)
                print(f"âŒ è¯·æ±‚ {result.get('request_id', '?')} å¤±è´¥: {result.get('error', 'Unknown error')}")
                print()

        # ç»Ÿè®¡ä¿¡æ¯
        print("=" * 100)
        print("ğŸ“Š è§†è§‰æ¨¡å‹æ€§èƒ½ç»Ÿè®¡:")
        print("=" * 100)

        if successful_requests:
            # è®¡ç®—å„ç§ç»Ÿè®¡æŒ‡æ ‡
            response_times = [r['total_time'] for r in successful_requests]
            tokens_per_second = [r['tokens_per_second'] for r in successful_requests if r['tokens_per_second'] > 0]
            total_tokens = sum(r['completion_tokens'] for r in successful_requests)
            total_prompt_tokens = sum(r['prompt_tokens'] for r in successful_requests)

            print(f"âœ… æˆåŠŸè¯·æ±‚: {len(successful_requests)}/{len(self.results)}")
            print(f"âŒ å¤±è´¥è¯·æ±‚: {len(failed_requests)}")
            print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}s")
            print(f"ğŸ¯ æ€»ç”ŸæˆToken: {total_tokens}")
            print(f"ğŸ“ æ€»è¾“å…¥Token: {total_prompt_tokens}")
            print()

            if response_times:
                print("â±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡:")
                print(f"   å¹³å‡: {statistics.mean(response_times):.2f}s")
                print(f"   æœ€å¿«: {min(response_times):.2f}s")
                print(f"   æœ€æ…¢: {max(response_times):.2f}s")
                print(f"   ä¸­ä½æ•°: {statistics.median(response_times):.2f}s")
                print()

            if tokens_per_second:
                print("âš¡ Tokenç”Ÿæˆé€Ÿåº¦ç»Ÿè®¡:")
                print(f"   å¹³å‡: {statistics.mean(tokens_per_second):.2f} tokens/s")
                print(f"   æœ€å¿«: {max(tokens_per_second):.2f} tokens/s")
                print(f"   æœ€æ…¢: {min(tokens_per_second):.2f} tokens/s")
                print(f"   ä¸­ä½æ•°: {statistics.median(tokens_per_second):.2f} tokens/s")
                print()

            # æ•´ä½“ååé‡
            overall_throughput = total_tokens / total_time if total_time > 0 else 0
            print(f"ğŸš€ æ•´ä½“ååé‡: {overall_throughput:.2f} tokens/s")
            print(f"ğŸ“ˆ å¹¶å‘æ•ˆç‡: {len(successful_requests) / total_time:.2f} requests/s")
            print(f"ğŸ–¼ï¸  å›¾ç‰‡å¤„ç†æ•ˆç‡: {len(successful_requests) / total_time:.2f} images/s")

        else:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚")

        print("=" * 100)


def get_vision_test_cases() -> List[Dict]:
    """è·å–è§†è§‰æµ‹è¯•ç”¨ä¾‹"""
    return [
        {
            "image_url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg",
            "text_prompt": "Describe this image in detail."
        },
        {
            "image_url": "https://ofasys-multimodal-wlcb-3-toshanghai.oss-accelerate.aliyuncs.com/wpf272043/keepme/image/receipt.png",
            "text_prompt": "Read all the text in the image."
        },
        {
            "image_url": "https://language.chinadaily.com.cn/images/attachement/jpg/site1/20160510/00221910993f189bf0bc52.jpg",
            "text_prompt": "Extract the full text from the newspaper exactly as it is, including every word."
        },
        {
            "image_url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg",
            "text_prompt": "What objects can you see in this image? List them."
        },
        {
            "image_url": "https://img2.baidu.com/it/u=3143282702,2145280608&fm=253&app=138&f=JPEG?w=800&h=1176",
            "text_prompt": "What characters do you see in this image?"
        },
        {
            "image_url": "https://img1.baidu.com/it/u=3809733790,1132788165&fm=253&app=138&f=JPEG?w=1422&h=800",
            "text_prompt": "What is the weather like in this image?"
        },
        {
            "image_url": "https://img1.baidu.com/it/u=4225257766,2460304301&fm=253&fmt=auto&app=138&f=JPEG?w=231&h=500",
            "text_prompt": "What character do you see in this image, and what mood does the character feel?"
        },
        {
            "image_url": "https://img2.baidu.com/it/u=500643173,2012953556&fm=253&fmt=auto&app=138&f=JPEG?w=500&h=1407",
            "text_prompt": "What characters do you see in this image and what might have happened between them?"
        },
        {
            "image_url": "https://h.cdn.zhuolaoshi.cn/user/site26644/image/20180927/20180927072723952395.jpg",
            "text_prompt": "What information can you extract from this image? "
                           "Please organize the extracted information into a structured format and present it."
        },
        {
            "image_url": "https://cje.ustb.edu.cn/fileGCKXXB/journal/article/gckxxb/2023/10/230315-0003-3.jpg",
            "text_prompt": "Analyze what you see in the picture."
        }
    ]


async def main():
    parser = argparse.ArgumentParser(description="vLLM è§†è§‰æ¨¡å‹å¹¶å‘æ€§èƒ½æµ‹è¯•å·¥å…·")
    parser.add_argument("--url", default="http://localhost:8001", help="vLLM æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--requests", "-r", type=int, default=3, help="å¹¶å‘è¯·æ±‚æ•°é‡")
    parser.add_argument("--max-tokens", type=int, default=512, help="æœ€å¤§ç”Ÿæˆtokenæ•°")
    parser.add_argument("--image-url", help="è‡ªå®šä¹‰å›¾ç‰‡URL")
    parser.add_argument("--text-prompt", help="è‡ªå®šä¹‰æ–‡æœ¬æç¤º")

    args = parser.parse_args()

    # å‡†å¤‡æµ‹è¯•ç”¨ä¾‹
    if args.image_url and args.text_prompt:
        # ä½¿ç”¨è‡ªå®šä¹‰çš„å›¾ç‰‡å’Œæç¤º
        test_cases = [
                         {
                             "image_url": args.image_url,
                             "text_prompt": args.text_prompt
                         }
                     ] * args.requests
    else:
        # ä½¿ç”¨é¢„å®šä¹‰çš„æµ‹è¯•ç”¨ä¾‹
        base_cases = get_vision_test_cases()
        test_cases = (base_cases * ((args.requests // len(base_cases)) + 1))[:args.requests]

    # åˆ›å»ºå®¢æˆ·ç«¯å¹¶è¿è¡Œæµ‹è¯•
    client = VisionConcurrentClient(args.url)
    await client.run_vision_concurrent_requests(test_cases, args.max_tokens)


if __name__ == "__main__":
    asyncio.run(main())
